#+PROPERTY: header-args:clojure :tangle ../../../../src/curbside/ml/models.clj :mkdirp yes :noweb yes :padline yes :results silent :comments link
#+OPTIONS: toc:2

#+TITLE: ML Algorithms Interface

* Table of Contents                                            :toc:noexport:
- [[#namespace-definition][Namespace definition]]
- [[#supported-algorithms][Supported algorithms]]
- [[#multimethods][Multimethods]]
  - [[#xgboost][XGBoost]]
  - [[#decision-trees][Decision trees]]
  - [[#svm][SVM]]
  - [[#linear-svm][Linear SVM]]
- [[#inference][Inference]]
- [[#evaluation][Evaluation]]
- [[#hyperparameters-optimization][Hyperparameters optimization]]
- [[#tests][Tests]]
  - [[#namespace-definition-1][Namespace definition]]
  - [[#hyperparameter-optimization-tests][Hyperparameter optimization tests]]

* Namespace definition

#+BEGIN_SRC clojure
(ns curbside.ml.models
  (:refer-clojure :exclude [load])
  (:require
   [clojure.data.csv :as csv]
   [clojure.java.io :as io]
   [clojure.math.combinatorics :as combinatorics]
   [clojure.spec.alpha :as s]
   [com.climate.claypoole :as cp]
   [curbside.ml.metrics :as metrics]
   [curbside.ml.models.xgboost :as xgboost]
   [curbside.ml.models.decision-trees :as decision-trees]
   [curbside.ml.models.linear-svm :as linear-svm]
   [curbside.ml.models.svm :as svm]
   [curbside.ml.utils.parsing :as parsing]
   [curbside.ml.utils.spec :as spec]
   [curbside.ml.training-sets.scaling :as scaling]
   [curbside.ml.training-sets.conversion :as conversion])
  (:import
   (java.io File)
   (java.util ArrayList)
   (weka.classifiers.evaluation NominalPrediction)))
#+END_SRC

* Supported algorithms

This library currently supports the following algorithms:

#+BEGIN_SRC clojure
(s/def ::algorithm #{:lsvm :svm :c4.5 :random-forest :m5p :xgboost})

(s/def ::predictor-type #{:regression :classification})
#+END_SRC

* Multimethods

All models implement a few common functions:

1. =save= to persist a trained model to disk.
2. =load= to load a trained model from disk.
3. =train= to train the model on a given problem.
4. =predict= to make a prediction
5. =dispose= to free allocated memory, if applicable

We will define multimethods for all of these operations. These multimethods will switch based on a keyword specifying the algorithm to use. Using a keyword allows us to easily specify the algorithm in the pipeline configs.

#+BEGIN_SRC clojure
(defmulti save
  (fn [algorithm model filepath]
    algorithm))

(defmulti load
  (fn [algorithm filepath]
    algorithm))

(defmulti load-from-bytes
  (fn [algorithm bytes]
    algorithm))

(defmulti train
  (fn [algorithm predictor-type training-set-path hyperparameters & args]
    algorithm))

(defmulti predict
  "Not meant to be called directly. Use =infer= instead."
  (fn [algorithm predictor-type model selected-features hyperparameters feature-vector]
    algorithm))

(defmulti dispose
  (fn [algorithm model]
    algorithm))

(defmethod dispose :default
  [_ _]
  nil)
#+END_SRC

** XGBoost

#+BEGIN_SRC clojure
(defmethod save :xgboost
  [_ model filepath]
  (xgboost/save model filepath))

(defmethod load :xgboost
  [_ filepath]
  (xgboost/load filepath))

(defmethod load-from-bytes :xgboost
  [_ bytes]
  (xgboost/load-from-bytes bytes))

(defmethod train :xgboost
  [_ _predictor-type training-set-path params & [weights-path]]
  (if weights-path
    (xgboost/train training-set-path params weights-path)
    (xgboost/train training-set-path params)))

(defmethod predict :xgboost
  [_ _predictor-type model _seleted-features hyperparameters feature-vector]
  (xgboost/predict model hyperparameters feature-vector))

(defmethod dispose :xgboost
  [_ model]
  (xgboost/dispose model))
#+END_SRC

** Decision trees

#+BEGIN_SRC clojure
(defmethod save :c4.5
  [_algorithm model filepath]
  (decision-trees/save model filepath))

(defmethod save :m5p
  [_algorithm model filepath]
  (decision-trees/save model filepath))

(defmethod save :random-forest
  [_algorithm model filepath]
  (decision-trees/save model filepath))

(defmethod load :c4.5
  [_ file]
  (decision-trees/load file))

(defmethod load :m5p
  [_ file]
  (decision-trees/load file))

(defmethod load :random-forest
  [_ file]
  (decision-trees/load file))

(defmethod load-from-bytes :c4.5
  [bytes]
  (decision-trees/load-from-bytes bytes))

(defmethod load-from-bytes :m5p
  [bytes]
  (decision-trees/load-from-bytes bytes))

(defmethod load-from-bytes :random-forest
  [bytes]
  (decision-trees/load-from-bytes bytes))

(defmethod train :c4.5
  [algorithm predictor-type training-set hyperparameters & _]
  (decision-trees/train algorithm predictor-type training-set hyperparameters))

(defmethod train :m5p
  [algorithm predictor-type training-set hyperparameters & _]
  (decision-trees/train algorithm predictor-type training-set hyperparameters))

(defmethod train :random-forest
  [algorithm predictor-type training-set hyperparameters & _]
  (decision-trees/train algorithm predictor-type training-set hyperparameters))

(defmethod predict :c4.5
  [_ predictor-type model selected-features _hyperparameters feature-vector]
  (decision-trees/predict predictor-type model selected-features feature-vector))

(defmethod predict :m5p
  [_ predictor-type model selected-features _hyperparameters feature-vector]
  (decision-trees/predict predictor-type model selected-features feature-vector))

(defmethod predict :random-forest
  [_ predictor-type model selected-features _hyperparameters feature-vector]
  (decision-trees/predict predictor-type model selected-features feature-vector))
#+END_SRC

** SVM

#+BEGIN_SRC clojure
(defmethod save :svm
  [_ model filepath]
  (svm/save model filepath))

(defmethod load :svm
  [_ filepath]
  (svm/load filepath))

(defmethod train :svm
  [_ _predictor-type training-set-path hyperparameters & _]
  (svm/train training-set-path hyperparameters))

(defmethod predict :svm
  [_ _predictor-type model seleted-features hyperparameters feature-vector]
  (svm/predict model seleted-features hyperparameters feature-vector))
#+END_SRC

** Linear SVM

#+BEGIN_SRC clojure
(defmethod save :lsvm
  [_ model filepath]
  (linear-svm/save model filepath))

(defmethod load :lsvm
  [_ filepath]
  (linear-svm/load filepath))

(defmethod load-from-bytes :lsvm
  [_ bytes]
  (linear-svm/load bytes))

(defmethod train :lsvm
  [_ _predictor-type training-set-csv-path hyperparameters & _]
  (linear-svm/train training-set-csv-path hyperparameters))

(defmethod predict :lsvm
  [_ _predictor-type model _selected-features _hyperparameters feature-vector]
  (linear-svm/predict model feature-vector))
#+END_SRC

* Inference

#+BEGIN_SRC clojure
(defn- parse-feature-map
  [selected-features feature-map]
  (reduce-kv #(assoc % %2 (parsing/parse-double %3))
             {}
             (select-keys feature-map selected-features)))

(defn- feature-scaling
  [feature-scaling-fns scaling-factors feature-map]
  (if feature-scaling-fns
    (scaling/scale-feature-map feature-scaling-fns scaling-factors feature-map)
    feature-map))

(defn- unscale-label
  [label-scaling-fns scaling-factors prediction]
  (if label-scaling-fns
    (scaling/unscale-label label-scaling-fns scaling-factors prediction)
    prediction))

(defn infer
  "This function performs the inference steps to perform predictions using a
  single trained model. It includes data preparation and post-processing
  operations required by all models. Such operations include:
  - Feature selection
  - Feature scaling (optional)
  - Querying a model prediction
  - Scaling the output of the model (optional)"
  [algorithm predictor-type model selected-features hyperparameters feature-map
   & {:keys [scaling-factors feature-scaling-fns label-scaling-fns]}]
  (->> feature-map
       (parse-feature-map selected-features)
       (feature-scaling feature-scaling-fns scaling-factors)
       (conversion/feature-map-to-vector selected-features)
       (predict algorithm predictor-type model selected-features hyperparameters)
       (unscale-label label-scaling-fns scaling-factors)))
#+END_SRC

* Evaluation

#+BEGIN_SRC clojure
(defn- to-temp-csv-path
  [header rows]
  (let [file (doto (File/createTempFile "data_" ".csv")
               (.deleteOnExit))]
    (with-open [w (io/writer file)]
      (csv/write-csv w (concat [header] rows)))
    (.getPath file)))

(defn- classify
  [actual predicted]
  (NominalPrediction. actual (NominalPrediction/makeDistribution predicted 2)))

(defn- evaluate-fold
  [algorithm selected-features hyperparameters feature-scaling-fns label-scaling-fns scaling-factors
   training-csv-path training-weights-path validation-set
   eval-atoms predictor-type predictions]
  (let [model (train algorithm predictor-type training-csv-path hyperparameters training-weights-path)]
    (doseq [[label & features] validation-set]
      (let [features-map (into {} (map vector selected-features features))
            predicted-value (infer algorithm predictor-type model selected-features hyperparameters features-map
                                   :scaling-factors scaling-factors
                                   :feature-scaling-fns nil ;; The features are already scaled in the training set.
                                   :label-scaling-fns label-scaling-fns)]
        (when (= predictor-type :classification)
          (.add predictions (classify (Double/parseDouble label) predicted-value)))
        (let [unscaled-label (unscale-label label-scaling-fns scaling-factors (parsing/parse-double label))
              diff (- unscaled-label predicted-value)
              abs-error (Math/abs diff)
              square-error (* diff diff)]
          (swap! (:abs-error eval-atoms) #(+ abs-error %))
          (swap! (:square-error eval-atoms) #(+ square-error %))
          (swap! (:n eval-atoms) inc))))
    (dispose algorithm model)))

(defn- zip
  [xs ys]
  (map vector xs ys))

(defn- unzip
  [xs]
  [(map first xs) (map second xs)])

(defn- load-weights
  "Loads the weights file, if it can be found and is non-empty. If not, return
   constant weights of the same length as the training set."
  [training-set example-weights-path]
  (try
    (with-open [in-file (io/reader example-weights-path)]
      (let [[_header & weights] (csv/read-csv in-file)]
        (if (not= (count weights) (count training-set))
          (repeat (count training-set) ["1.0"])
          weights)))
    (catch Exception _
      (repeat (count training-set) ["1.0"]))))

(defn- cross-validate
  "Evaluate the performance of a model using k-fold cross-validation. Takes a
  training set CSV file as input and the number of `k-folds` to use for the
  cross validation. If `multithreads` is `true`, then each fold will be
  processed on its own thread in parallel."
  [algorithm predictor-type selected-features hyperparameters training-set-path
   {:as _options :keys [k-folds multithreads scaling-factors feature-scaling-fns
                        label-scaling-fns example-weights-path]}]
  {:pre [(some #{:classification :regression} #{predictor-type})]}
  (let [k-folds (or k-folds 10)
        multithreads (or multithreads false)
        [header & training-set] (with-open [in-file (io/reader training-set-path)]
                                  (doall
                                   (csv/read-csv in-file)))
        weights (load-weights training-set example-weights-path)
        folds (partition-all (/ (count training-set) k-folds) (shuffle (zip training-set weights)))
        eval-atoms {:n (atom 0)
                    :abs-error (atom 0)
                    :square-error (atom 0)}
        predictions (ArrayList.)
        futures (atom [])]
    (loop [processed-folds 1
           [validation-set validation-weights] (unzip (first folds))
           training-set-folds (rest folds)]
      (let [training-csv-path (to-temp-csv-path header (apply concat (map (partial map first) training-set-folds)))
            training-weights-path (to-temp-csv-path ["weight"] (apply concat (map (partial map second) training-set-folds)))]
        (when (<= processed-folds k-folds)
          (if multithreads
            (swap! futures conj (future (evaluate-fold algorithm
                                                       selected-features
                                                       hyperparameters
                                                       feature-scaling-fns
                                                       label-scaling-fns
                                                       scaling-factors
                                                       training-csv-path
                                                       training-weights-path
                                                       validation-set
                                                       eval-atoms
                                                       predictor-type
                                                       predictions)))
            (evaluate-fold algorithm
                           selected-features
                           hyperparameters
                           feature-scaling-fns
                           label-scaling-fns
                           scaling-factors
                           training-csv-path
                           training-weights-path
                           validation-set
                           eval-atoms
                           predictor-type
                           predictions))
          (recur (inc processed-folds)
                 (unzip (first training-set-folds))
                 (conj (rest training-set-folds) (zip validation-set validation-weights))))))
    (when multithreads
      (doseq [f @futures]
        @f))

    (metrics/model-metrics predictor-type predictions eval-atoms)))

(defn evaluate
  "Only cross-validate method is supported at the moment."
  [algorithm predictor-type selected-features hyperparameters training-set-path
   & {:keys [_k-folds _multithreads _scaling-factors _feature-scaling-fns _label-scaling-fns _example-weights-path] :as options}]
  (cross-validate algorithm predictor-type selected-features hyperparameters training-set-path options))
#+END_SRC

* Hyperparameters optimization

We generate the various combinations of the hyperparameters to be tried in order to get the best hyperparameters. Each combination is used to train a model with the sampled data and then the best parameters are selected.

The supported hyperparameter search functions are the following:
1. Grid Search: we exhaustively try each and every combination possible from the given search space. Note that for continuous values, it is still required to specify a finite list of values to try.
2. Random Search: From the given search space, we randomly pick values, the search space can consist of integers, decimals and strings. The integer and decimal spaces are defined by min (inclusive)
   and max (exclusive) while the string can take a finite set of values defined in "values" provided as a list. The total number of combinations tried are defined by "iteration-count" defined in
   "hyperparameter-search-fn". This would allow us to explore values inside the continous search space which need not be explicitly defined the config like a grid search. Also, random search would
   allow us to achieve comparable results to grid search much faster due to lesser number of iterations (depending on the number of combinations tried in grid search and iteration count).

#+BEGIN_SRC clojure
(def supported-hyperparameter-search-fn-types #{:grid :random})

(s/def :hyperparameter-search-fn/type supported-hyperparameter-search-fn-types)

(s/def ::hyperparameter-search-fn-common
  (s/keys :req-un [:hyperparameter-search-fn/type]))

(defmulti hyperparameter-search-fn :type)

(defmethod hyperparameter-search-fn :grid [_]
  ::hyperparameter-search-fn-common)

(s/def ::iteration-count int?)

(defmethod hyperparameter-search-fn :random [_]
  (s/merge
    ::hyperparameter-search-fn-common
    (s/keys :req-un [::iteration-count])))

(s/def ::hyperparameter-search-fn (s/multi-spec hyperparameter-search-fn :type))

(def supported-random-search-space-dimension-types #{"integer" "decimal" "string"})

(s/def :random-search-space-dimension/type supported-random-search-space-dimension-types)

(s/def ::random-search-space-dimension-common
  (s/keys :req-un [:random-search-space-dimension/type]))

(s/def :string/values (s/coll-of string? :distinct true))

(s/def ::random-search-space-dimension-string (s/keys :req-un [:string/values]))

(s/def :decimal/min (s/double-in :infinite? false :NaN? false))
(s/def :decimal/max (s/double-in :infinite? false :NaN? false))
(s/def ::random-search-space-dimension-decimal (s/and (s/keys :req-un [:decimal/min :decimal/max])
                                                   (fn [{:keys [min max]}] (< min max))))

(s/def :integer/min (s/int-in Integer/MIN_VALUE Integer/MAX_VALUE))
(s/def :integer/max (s/int-in Integer/MIN_VALUE Integer/MAX_VALUE))
(s/def ::random-search-space-dimension-integer (s/and (s/keys :req-un [:integer/min :integer/max])
                                                   (fn [{:keys [min max]}] (< min max))))

(defmulti random-search-space-dimension :type)

(defmethod random-search-space-dimension "integer" [_]
  (s/merge
    ::random-search-space-dimension-integer
    ::random-search-space-dimension-common))

(defmethod random-search-space-dimension "decimal" [_]
  (s/merge
    ::random-search-space-dimension-decimal
    ::random-search-space-dimension-common))

(defmethod random-search-space-dimension "string" [_]
  (s/merge
    ::random-search-space-dimension-string
    ::random-search-space-dimension-common))

(s/def ::random-search-space-dimension (s/multi-spec random-search-space-dimension :type))

(s/def ::hyperparameter-search-random-space-key-check keyword?)

(s/def ::hyperparameter-search-space-random
    (s/map-of ::hyperparameter-search-random-space-key-check ::random-search-space-dimension))

(s/def ::hyperparameter-search-space-grid (s/map-of keyword?
                                               (s/coll-of (s/or :double (s/double-in :infinite? false :NaN? false)
                                                                :integer integer?
                                                                :string string?) :distinct true)))

(s/def ::hyperparameter-search-space (s/or :random ::hyperparameter-search-space-random
                                           :grid ::hyperparameter-search-space-grid))

;; Algorithm specific hyperparameters

(s/def ::hyperparameters (s/or :lsvm ::linear-svm/hyperparameters
                               :svm ::svm/hyperparameters
                               :c45 ::decision-trees/c45-hyperparameters
                               :m5p ::decision-trees/m5p-hyperparameters
                               :rf ::decision-trees/rf-hyperparameters
                               :xgboost ::xgboost/hyperparameters))

(defn- grid-search-combos
  "Given the hyperparameter search space, returns all possible combinations of
  parameters."
  [hyperparameter-search-space]
  (->> (vals hyperparameter-search-space)
       (apply combinatorics/cartesian-product)
       (map #(into {} (map (fn [x y] [x y])
                           (keys hyperparameter-search-space)
                           %)))))

(defn- random-value
  "Generate random values for the given set of parameter constraints which are
   used for random search"
  [{:keys [min max type values]}]
  (case type
    "integer" (+ (rand-int (- max min)) min)
    "decimal" (+ (rand (- max min)) min)
    "string" (rand-nth values)))

(defn- random-search-combos
  "Given the hyperparameter search space, generate a given number of random
  combinations of parameters"
  [iteration-count hyperparameter-search-space]
  (repeatedly iteration-count
              #(into {} (map (fn [[key value]] [key (random-value value)])
              hyperparameter-search-space))))

(defn optimize-hyperparameters
  "This function is responsible for training a model with the best
  hyperparameters found by the provided `hyperparameter-search-fn`."
  [algorithm predictor-type selected-features hardcoded-hyperparameters hyperparameter-search-fn hyperparameter-search-space training-set-path
   & {:keys [selection-metric k-folds threads-pool scaling-factors feature-scaling-fns
             label-scaling-fns example-weights-path]}]
  {:pre [(spec/check ::algorithm algorithm)
         (spec/check ::predictor-type predictor-type)
         (spec/check ::hyperparameters hardcoded-hyperparameters)
         (spec/check (s/nilable ::hyperparameter-search-fn) hyperparameter-search-fn)
         (spec/check ::hyperparameter-search-space hyperparameter-search-space)]}
  (let [hyperparameter-search-fn (or hyperparameter-search-fn {:type :grid})
        selection-metric (or selection-metric :root-mean-square-error)
        k-folds (or k-folds 2)
        thread-count (or threads-pool 1)
        combos (case (:type hyperparameter-search-fn)
                 :grid (grid-search-combos hyperparameter-search-space)
                 :random (random-search-combos (:iteration-count hyperparameter-search-fn)
                    hyperparameter-search-space))
        eval (fn [hyperparameters-to-optimize]
               (let [hyperparameters (merge hardcoded-hyperparameters hyperparameters-to-optimize)
                     result (evaluate algorithm
                                      predictor-type
                                      selected-features
                                      hyperparameters
                                      training-set-path
                                      :scaling-factors scaling-factors
                                      :k-folds k-folds
                                      :feature-scaling-fns feature-scaling-fns
                                      :label-scaling-fns label-scaling-fns
                                      :example-weights-path example-weights-path)]
                 {:optimal-params hyperparameters
                  :selected-evaluation (get result selection-metric)
                  :model-evaluations result}))
        find-best (if (= (metrics/comparator selection-metric) <)
                    min-key
                    max-key)
        evaluated-combos (cp/with-shutdown! [pool thread-count]
                           (->> combos
                                (cp/pmap pool eval)
                                (doall)))
        best-evaluation (apply find-best :selected-evaluation evaluated-combos)]
    best-evaluation))
#+END_SRC

* Tests

** Namespace definition

#+NAME: test-namespace
#+BEGIN_SRC clojure :tangle ../../../../test/curbside/ml/models_test.clj
(ns curbside.ml.models-test
  (:require
   [clojure.test :refer [deftest is testing]]
   [curbside.ml.models :as models]
   [conjure.core :refer [stubbing verify-call-times-for verify-first-call-args-for]]
   [curbside.ml.utils.tests :as tutils]))
#+END_SRC

** Hyperparameter optimization tests

Here, the goal is simply test if we can get models with optimal parameters
First, we setup some values that will be used in the tests

#+BEGIN_SRC clojure :tangle ../../../../test/curbside/ml/models_test.clj
(def grid-search-combos-stub-value [{:subsample 0.5, :max_depth 5}
                                    {:subsample 0.5, :max_depth 6}
                                    {:subsample 0.5, :max_depth 7}
                                    {:subsample 0.6, :max_depth 5}
                                    {:subsample 0.6, :max_depth 6}
                                    {:subsample 0.6, :max_depth 7}])

(def random-search-combos-stub-value [{:subsample 0.5643362797872074, :max_depth 6, :booster "dart"}
                                      {:subsample 0.5307578644935428, :max_depth 6, :booster "dart"}
                                      {:subsample 0.9486528438903652, :max_depth 6, :booster "dart"}
                                      {:subsample 0.7317135931408416, :max_depth 8, :booster "dart"}
                                      {:subsample 0.8114551550463982, :max_depth 5, :booster "dart"}
                                      {:subsample 0.5224498589316126, :max_depth 8, :booster "dart"}
                                      {:subsample 0.9091339560549907, :max_depth 5, :booster "dart"}
                                      {:subsample 0.6190130901825939, :max_depth 8, :booster "dart"}
                                      {:subsample 0.8268034625457685, :max_depth 7, :booster "dart"}
                                      {:subsample 0.8190881875862341, :max_depth 5, :booster "dart"}])

(def hyperparameter-search-space-random {:subsample {:min  0.5 :max  0.99 :type "decimal"}
                                         :max_depth {:min  5 :max  9 :type "integer"}
                                         :booster   {:type   "string" :values ["dart"]}})

(deftest test-optimize-hyperparameters-grid
  (testing "Check if optimize hyperparameters returns a model with all valid sets of hyperparameters according to given spec or not for grid search"
    (tutils/stubbing-private [models/grid-search-combos grid-search-combos-stub-value]
      (let [hyperparameters {:eval_metric "mae" :booster "dart"}
            hyperparameter-search-space-grid {:subsample [0.5 0.6] :max_depth [5 6 7]}
            hyperparameter-search-fn {:type :grid}
            {:keys [optimal-params model-evaluations]} (models/optimize-hyperparameters :xgboost
                                                                                        :regression
                                                                                        ["lat" "lng"]
                                                                                        hyperparameters
                                                                                        hyperparameter-search-fn
                                                                                        hyperparameter-search-space-grid
                                                                                        tutils/dummy-regression-single-label-training-set-path)]
        (verify-call-times-for models/grid-search-combos 1)
        (verify-first-call-args-for models/grid-search-combos hyperparameter-search-space-grid)
        (is (tutils/approx= 0.6 (:subsample optimal-params) 1e-1))
        (is (= {:subsample 0.6, :max_depth 7 :booster "dart" :eval_metric "mae"} optimal-params))
        (is (tutils/approx= 0.04606 (:mean-absolute-error model-evaluations) 1e-4))
        (is (tutils/approx= 0.04606 (:root-mean-square-error model-evaluations) 1e-4))))))

(deftest test-optimize-hyperparameters-random
  (testing "Check if optimize hyperparameters returns a model with all valid sets of hyperparameters according to given spec or not"
    (tutils/stubbing-private [models/random-search-combos random-search-combos-stub-value]
      (let [hyperparameters {:eval_metric "mae" :booster "dart"}
            hyperparameter-search-fn {:type :random :iteration-count 10}
            {:keys [optimal-params model-evaluations]} (models/optimize-hyperparameters :xgboost
                                                                                        :regression
                                                                                        ["lat" "lng"]
                                                                                        hyperparameters
                                                                                        hyperparameter-search-fn
                                                                                        hyperparameter-search-space-random
                                                                                        tutils/dummy-regression-single-label-training-set-path)]
        (verify-call-times-for models/random-search-combos 1)
        (verify-first-call-args-for models/random-search-combos 10 hyperparameter-search-space-random)
        (println optimal-params)
        (is (tutils/approx= 0.9486 (:subsample optimal-params) 1e-4))
        (is (= {:subsample 0.9486528438903652 :max_depth 6 :booster "dart" :eval_metric "mae"} optimal-params))
        (is (tutils/approx= 0.0277 (:mean-absolute-error model-evaluations) 1e-4))
        (is (tutils/approx= 0.0277 (:root-mean-square-error model-evaluations) 1e-4))))))
#+END_SRC
