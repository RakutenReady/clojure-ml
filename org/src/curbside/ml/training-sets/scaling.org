#+PROPERTY: header-args:clojure :tangle ../../../../../src/curbside/ml/training_sets/scaling.clj :mkdirp yes :noweb yes :padline yes :results silent :comments link
#+OPTIONS: toc:2

#+TITLE: Training-set Scaling

* Table of Contents                                             :toc:noexport:
- [[#introduction][Introduction]]
  - [[#namespaces-definition][Namespaces definition]]
- [[#dispatch-function][Dispatch function]]
- [[#scaling-factors-structure][Scaling factors structure]]
- [[#min-max-scaling][=min-max= scaling]]
- [[#log10-label-scaling][=log10-label= scaling]]
- [[#scale-training-set][Scale training-set]]
- [[#scale-feature-map-for-inference][Scale feature map for inference]]
- [[#tests][Tests]]
  - [[#namespaces-definition-1][Namespaces definition]]
  - [[#test-min-max][Test =min-max=]]
  - [[#test-log10][Test =log10=]]
  - [[#test-scaling-training-sets][Test scaling training sets]]
  - [[#test-unscaling-inference][Test unscaling inference]]

* Introduction

Feature scaling is a method used to standardize the range of independent variables or features of data. Depending on the training algorithm (like SVM), one of the most important task of the creation of the training set is to normalize the feature's values to help the algorithm to learn.

We support two types of scaling:
- feature scaling :: as its name suggests, it is scaling applied to the input features of a model
- label scaling :: scaling applied to only the =:label= key of a feature map.

The key distinction between the two types of scaling is that label scaling *also needs to be applied on predicted values at inference time*. The scaling configuration spec is detailed [[file:~/curbside-prediction/org/src/curbside/prediction/pipeline.org::*Scale%20Training%20Sets][here]].

** Namespaces definition

#+BEGIN_SRC clojure
(ns curbside.ml.training-sets.scaling
  "The model namespace includes all the functions related to scaling training-sets features and labels"
  (:require
   [clojure.spec.alpha :as s]
   [curbside.ml.training-sets.conversion :as conversion]
   [medley.core :as medley]))
#+END_SRC

* Dispatch function

#+BEGIN_SRC clojure
(defmulti compute-factors
  "Given a scaling function, `compute-factors` produces the map of factor
  parameters passed to each `apply-scaling` and `apply-uncaling` call."
  (fn [scaling-fn _training-set]
    scaling-fn))

(defmulti apply-scaling
  "Scales a `value` according to the provided `factors`."
  (fn [scaling-fn _value _value-factors]
    scaling-fn))

(defmulti apply-unscaling
  "Unscales a `value` according to the provided `factors`."
  (fn [scaling-fn _value _value-factors]
    scaling-fn))
#+END_SRC

#+BEGIN_SRC clojure
(defn scale-map-keys
  [scaling-fn map factors]
  (medley/map-kv-vals (fn [key val]
                        (if-let [key-factors (get factors key)]
                          (when val (apply-scaling scaling-fn val key-factors))
                          val))
                      map))
#+END_SRC

* Scaling factors structure

Given a training set, a =factors= data structure is produced and saved on S3. This allows to reproduce the same scaling at inference that we applied at training time.

Here is an example =factors= data structure:

#+BEGIN_SRC clojure :tangle no :results silent :exports code
{:features [{:x {:min 10
                 :max 12}
             :y {:min 0
                 :max 20}}]
 :labels [{:min 10 :max 30}]
#+END_SRC

=factors= is a map which contains two keys:
- =:features= :: Factors of the =:feature-scaling-fns=. It is a vector of maps, where each map contains the factors of a given scaling functions. For each =:feature-scaling-fns=, the key represents the feature which is scaled, and the value is the factors used to scaled this feature.
- =:labels= :: Factors of the =:label-scaling-fns=. It is a vector of maps. Unlike the =:features= key, there is only one value scale, namely the label.
Here's the spec

#+BEGIN_SRC clojure
(s/def ::min number?)
(s/def ::max number?)
(s/def ::min-max-factors (s/and (s/keys :req-un [::min ::max])
                                (fn [{:keys [min max]}]
                                  (< min max))))
(s/def ::log10-factors map?)

(s/def ::value-factors (s/or :min-max ::min-max-factors
                             :log10 ::log10-factors))

(s/def ::features (s/coll-of (s/map-of keyword? ::value-factors)))
(s/def ::labels (s/coll-of ::value-factors))
(s/def ::training-set-factors (s/keys :req-un [::features ::labels]))
#+END_SRC

* =min-max= scaling

Scaling the values between \([0, 1]\) can easily be done using this formula min-max scaling:

\(x' = \frac{x - \text{min}(x)}{\text{max}(x)-\text{min}(x)}\)

where \(x\) is an original value and \(x'\) is the normalized value.

The first thing we have to do is to find the minimal and the maximal value for each feature and then apply this formula to each of the features' value and save that in the scaled training file.

We have to take care of the =nil= values since the training set is a sparse matrix. This means that we have to take care of the possible =nil= values when checking the =max= or =min= values of a column.

#+NAME: min max of each feature
#+BEGIN_SRC clojure
(defn- min-max-feature
  [feature training-set]
  (let [values (keep feature training-set)]
    (if (empty? values)
      {:min Double/MIN_VALUE :max Double/MAX_VALUE}
      {:min (apply min values) :max (apply max values)})))

(defmethod compute-factors :min-max
  [_ training-set]
  (let [features (remove #(= :label %) (keys (first training-set)))]
    (reduce (fn [factors feature]
              (assoc factors feature (min-max-feature feature training-set)))
            {}
            features)))
#+END_SRC

Here are the formulas to scale and un-scale a value using min-max scaling:

#+NAME: csv features scale
#+BEGIN_SRC clojure
(defmethod apply-scaling :min-max
  [_ value {:keys [min max] :as factors}]
  {:pre [(s/valid? ::min-max-factors factors)]}
  (let [denom (- max min)]
    (/ (- value min)
       (if (> denom 0) denom 1))))

(defmethod apply-unscaling :min-max
  [_ value {:keys [min max] :as factors}]
  {:pre [(s/valid? ::min-max-factors factors)]}
  (+ min
     (* value (- max min))))
#+END_SRC

* =log10-label= scaling

This scaling function applies a =log10= operation to the label. This has been shown in research that this scaling function gives more importance to small label values, improving the overall MAPE metrics.

To avoid the =Infinity= values in computation, the minimum value produced by log10 scaling if =1e-8= and the maximum value produced by the unscaling is =1e8=

#+BEGIN_SRC clojure
(def min-log10-value 1e-8)
(def max-log10-value 1e8)

(defmethod compute-factors :log10
  [& _args]
  {}) ;; Empty map, no factors needs to be saved for this scaling function

(defmethod apply-scaling :log10
  [_ value _value-factors]
  (max min-log10-value (Math/log10 (max 0 value))))

(defmethod apply-unscaling :log10
  [_ value _value-factors]
  (min max-log10-value (Math/pow 10 value)))
#+END_SRC

* Scale training-set

Next, we define functions to scale a whole training set. We define functions to scale a feature map, a collection of feature map and a CSV training set.

#+BEGIN_SRC clojure
(defn scale-feature-map
  "Scales a `feature-map`, applying in order the `scaling-fns` to all features
  present in the `factors` map."
  [scaling-fns factors feature-map]
  (reduce (fn [feature-map [scaling-fn factors]]
            (scale-map-keys scaling-fn feature-map factors))
          feature-map
          (map vector scaling-fns (:features factors))))

(defn scale-training-set-features
  "Scales the features a training set, which is a collection of feature maps."
  [scaling-fns factors training-set]
  (map (partial scale-feature-map scaling-fns factors) training-set))

(defn scale-training-set-labels
  "Scales the `:label` key of the all the feature maps, successively applying
  the `scaling-fns`."
  [scaling-fns factors training-set]
  (reduce (fn [training-set [scaling-fn factors]]
            (map #(update % :label (partial apply-scaling scaling-fn) factors) training-set))
          training-set
          (map vector scaling-fns (:labels factors))))

(defn scale-training-set
  "Scales the features and the labels of a training set."
  [feature-scaling-fns label-scaling-fns factors training-set]
  {:pre [(s/valid? ::training-set-factors factors)]}
  (->> training-set
       (scale-training-set-features feature-scaling-fns factors)
       (scale-training-set-labels label-scaling-fns factors)))

(defn- scaling-factors
  "Compute the `factors` used to scale a training set."
  [feature-scaling-fns label-scaling-fns training-set]
  (letfn [(compute-all-factors [scaling-fns]
            (mapv #(compute-factors % training-set) scaling-fns))]
    {:features (compute-all-factors feature-scaling-fns)
     :labels (compute-all-factors label-scaling-fns)}))

(defn scale-training-set-csv
  "Scales a training set encoded in the file at `input-csv-path`. The scaled set
  is outputted at `outpt-csv-file`, and the scaling factors used to perform
  scaling are saved at `edn-factors-path`."
  [input-csv-path output-csv-file edn-factors-path feature-scaling-fns label-scaling-fns]
  (let [training-set        (conversion/csv-to-maps input-csv-path)
        factors             (scaling-factors feature-scaling-fns label-scaling-fns training-set)
        scaled-set          (scale-training-set feature-scaling-fns label-scaling-fns factors training-set)]
    (spit edn-factors-path (pr-str factors))
    (conversion/maps-to-csv output-csv-file
                            (conversion/csv-column-keys input-csv-path)
                            scaled-set)))
#+END_SRC

* Scale feature map for inference

At inference time, we need to unscale the predicted value to obtain a prediction that is in the source domain.

#+BEGIN_SRC clojure
(defn unscale-inference
  "Unscaled a single value, successively unscaling the `scaling-fns` in reverse
  order."
  [scaling-fns factors value]
  {:pre [(s/valid? ::training-set-factors factors)]}
  (reduce (fn [value [scaling-fn factors]]
            (apply-unscaling scaling-fn value factors))
          value
          (reverse (map vector scaling-fns (:labels factors)))))
#+END_SRC

* Tests
** Namespaces definition

#+NAME: unit test namespaces
#+BEGIN_SRC clojure :tangle ../../../../../test/curbside/ml/training_sets/scaling_test.clj
(ns curbside.ml.training-sets.scaling-test
  (:require
   [clojure.test :refer [deftest is testing]]
   [curbside.ml.training-sets.scaling :as scaling]))
#+END_SRC

** Test =min-max=

#+BEGIN_SRC clojure :tangle ../../../../../test/curbside/ml/training_sets/scaling_test.clj
(def a-feature-map {:x 10 :y  -2 :z 1000 :unknown nil :label 10})

(def min-max-features-factors {:x {:min 0 :max 20} :y {:min -5 :max 5}})

(deftest test-min-max-scaling
  (testing "given a number, when scaling and unscaling it, then it still have the same value"
    (is (as-> 2 value
            (scaling/apply-scaling :min-max value {:min 0 :max 10})
            (scaling/apply-unscaling :min-max value {:min 0 :max 10})
            (== 2 value))))

  (testing "given a number, when applying scaling, then the number is scaled"
    (is (== 0.2 (scaling/apply-scaling :min-max 2 {:min 0 :max 10}))))

  (testing "given a number, when applying unscaling, then the number is unscaled"
    (is (== -10 (scaling/apply-unscaling :min-max 0 {:min -10 :max 0}))))

  (testing "given a feature map and scaling factors, when applying scaling, all features in the factor map are scaled"
    (let [scaled-map (scaling/scale-map-keys :min-max a-feature-map min-max-features-factors)]
      (is (== 0.5 (:x  scaled-map)))
      (is (== 0.3 (:y  scaled-map)))
      (is (== 1000 (:z  scaled-map)))
      (is (nil? (:unknown  scaled-map)))
      (is (== 10 (:label scaled-map))))))
#+END_SRC

** Test =log10=

#+BEGIN_SRC clojure :tangle ../../../../../test/curbside/ml/training_sets/scaling_test.clj
(def log10-features-factors {:x {} :z {}})

(deftest test-log10-scaling
  (testing "given a number, when scaling and unscaling it, then it still have the same value"
    (is (as-> 2 value
          (scaling/apply-scaling :log10 value {})
          (scaling/apply-unscaling :log10 value {})
          (== 2 value))))

  (testing "given a number, when applying scaling, then the number is scaled"
    (is (== 1 (scaling/apply-scaling :log10 10 nil))))

  (testing "given a number, when applying unscaling, then the number is unscaled"
    (is (== 10 (scaling/apply-unscaling :log10 1 nil))))

  (testing "given a feature map and scaling factors, when applying scaling, all features in the factor map are scaled"
    (let [scaled-map (scaling/scale-map-keys :log10 a-feature-map log10-features-factors)]
      (is (== 1 (:x  scaled-map)))
      (is (== -2 (:y  scaled-map)))
      (is (== 3 (:z  scaled-map)))
      (is (nil? (:unknown  scaled-map)))
      (is (== 10 (:label scaled-map))))))

(deftest test-log10-scaling-min-max-values
  (testing "given a negative value, when applying scaling, it returns a small value instead of negative infinity"
    (is (== scaling/min-log10-value (scaling/apply-scaling :log10 -2 nil)))))
#+END_SRC

** Test scaling training sets

#+BEGIN_SRC clojure :tangle ../../../../../test/curbside/ml/training_sets/scaling_test.clj
(def a-training-set (repeat 3 a-feature-map))
(def training-set-scaling-factors {:features [min-max-features-factors]
                                 :labels [{}]})

(defn is-training-set-example-scaled?
  [{:keys [x y z unknown label]}]
  (is (== 0.5 x))
  (is (== 0.3 y))
  (is (== 1000 z))
  (is (nil? unknown))
  (is (== 1 label)))

(deftest test-scale-training-set
  (testing "given a training set, when scaling, all features and labels are scaled"
    (let [scaled-set (scaling/scale-training-set [:min-max]
                                                 [:log10]
                                                 training-set-scaling-factors
                                                 a-training-set)]
      (doseq [example scaled-set]
        (is-training-set-example-scaled? example)))))
#+END_SRC

** Test unscaling inference

#+BEGIN_SRC clojure :tangle ../../../../../test/curbside/ml/training_sets/scaling_test.clj
(deftest test-unscale-inference
  (testing "given an inferred value, when unscaling, the value is unscaled"
    (is (== 0.1 (scaling/unscale-inference [:log10] training-set-scaling-factors -1))))
  (testing "given multiple scaling functions, when unscaling, the value is unscaled."
    (let [factors {:features [] :labels [{:min 0 :max 100} {}]}]
      (is (== 100 (scaling/unscale-inference [:min-max :log10] factors 0))))))
#+END_SRC
